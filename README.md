## ðŸ“– Face Generation and Editing with StyleGAN: A Survey

Survey link: https://arxiv.org/abs/2212.09102

```
@article{melnik2022face,
  title={Face Generation and Editing with StyleGAN: A Survey},
  author={Melnik, Andrew and Miasayedzenkau, Maksim and Makarovets, Dzianis and Pirshtuk, Dzianis and Akbulut, Eren and Holzmann, Dennis and Renusch, Tarek and Reichert, Gustav and Ritter, Helge},
  journal={arXiv preprint arXiv:2212.09102},
  year={2022}
}
```

---

## Papers
[Click to see Figures](#papers)  
- [2023](#2023), [2022](#2022), [2021](#2021), [2020](#2020), [2019](#2019), [2018](#2018), [2017](#2017), [2016](#2016)
## 2023  

ðŸ“„<b> FastSwap: A Lightweight One-Stage Framework for Real-Time Face Swapping </b> <br />
<sub>[[Paper]](https://openaccess.thecvf.com/content/WACV2023/papers/Yoo_FastSwap_A_Lightweight_One-Stage_Framework_for_Real-Time_Face_Swapping_WACV_2023_paper.pdf)  [[Project]](https://wacv-1752.github.io/FastSwap/) [[Github]](https://github.com/sahngmin/fastswap) WACV</sub><br /> <sub><sup>Sahng-Min Yoo, Tae-Min Choi, Jae-Woo Choi, Jong-Hwan Kim</sup></sub>  

<b>LinkGAN: Linking GAN Latents to Pixels for Controllable Image Synthesis </b>  
<sub>[[Paper]](https://arxiv.org/abs/2301.04604)  [[Project]](https://zhujiapeng.github.io/linkgan/) [[Github]](https://github.com/zhujiapeng/linkgan) arxiv</sub> <sub><sub><sup>Jiapeng Zhu, Ceyuan Yang, Yujun Shen, Zifan Shi, Deli Zhao, Qifeng Chen</sup></sub></sub>  

ðŸ“„<b> SLI-pSp: Injecting Multi-Scale Spatial Layout in pSp </b> <br />
[[Paper]](https://openaccess.thecvf.com/content/WACV2023/papers/Mathur_SLI-pSp_Injecting_Multi-Scale_Spatial_Layout_in_pSp_WACV_2023_paper) WACV<br />
<sub><sup>Aradhya Neeraj Mathur, Anish Madan, Ojaswa Sharma</sup></sub><br />

## 2022<br />

ðŸ“„<b> Face Generation and Editing with StyleGAN: A Survey </b> <br />
[[Paper]](https://arxiv.org/abs/2212.09102) arxiv<br />
<sub><sup>Andrew Melnik, Maksim Miasayedzenkau, Dzianis Makarovets, Dzianis Pirshtuk, Eren Akbulut, Dennis Holzmann, Tarek Renusch, Gustav Reichert, Helge Ritter</sup></sub><br />

ðŸ“„<b> 3D Cartoon Face Generation with Controllable Expressions from a Single GAN Image </b> <br />
[[Paper]](https://arxiv.org/abs/2207.14425) arxiv<br />
<sub><sup>Hao Wang, Guosheng Lin, Steven C. H. Hoi, Chunyan Miao</sup></sub><br />

ðŸ“„<b> Faces: AI Blitz XIII Solutions </b> <br />
[[Paper]](https://arxiv.org/abs/2204.01081)  [[Github]](https://github.com/ndrwmlnk/ai-blitz-xiii) arxiv<br />
<sub><sup>Andrew Melnik, Eren Akbulut, Jannik Sheikh, Kira Loos, Michael Buettner, Tobias Lenze</sup></sub><br />

ðŸ“„<b> MyStyle: A Personalized Generative Prior </b> <br />
[[Paper]](https://arxiv.org/abs/2203.17272) [[Github]](https://mystyle-personalized-prior.github.io/) [[Video]](https://www.youtube.com/watch?v=axWo_9Gt47o) arxiv<br />
<sub><sup>Yotam Nitzan, Kfir Aberman, Qiurui He, Orly Liba, Michal Yarom, Yossi Gandelsman, Inbar Mosseri, Yael Pritch, Daniel Cohen-or</sup></sub><br />

ðŸ“„<b> Third Time's the Charm? Image and Video Editing with StyleGAN3 </b> <br />
[[Paper]](https://arxiv.org/abs/2201.13433)  [[Github]](https://github.com/yuval-alaluf/stylegan3-editing) arxiv<br />
<sub><sup>Yuval Alaluf, Or Patashnik, Zongze Wu, Asif Zamir, Eli Shechtman, Dani Lischinski, Daniel Cohen-Or</sup></sub><br />

ðŸ“„<b> E2Style: Improve the Efficiency and Effectiveness of StyleGAN Inversion </b> <br />
[[Paper]](https://arxiv.org/abs/2201.13433)  [[Github]](https://github.com/wty-ustc/e2style) IEEE Transactions on Image Processing<br />
<sub><sup>Tianyi Wei, Dongdong Chen, Wenbo Zhou, Jing Liao, Weiming Zhang, Lu Yuan, Gang Hua, Nenghai Yu</sup></sub><br />

ðŸ“„<b> Unsupervised face frontalization using disentangled representation-learning CycleGAN </b> <br />
[[Paper]](https://www.sciencedirect.com/science/article/abs/pii/S1077314222001096) Computer Vision and Image Understanding<br />
<sub><sup>Yanfei Liu Junhua Chen</sup></sub><br />

## 2021<br />

ðŸ“„<b> HyperStyle: StyleGAN Inversion with HyperNetworks for Real Image Editing </b> <br />
[[Paper]](https://arxiv.org/abs/2111.15666) [[Github]](https://github.com/yuval-alaluf/hyperstyle) [[Video]](https://www.youtube.com/watch?v=_sbXmLY2jMw) CVPR<br />
<sub><sup>Yuval Alaluf, Omer Tov, Ron Mokady, Rinon Gal, Amit H. Bermano</sup></sub><br />

ðŸ“„<b> Fine-Tuning StyleGAN2 For Cartoon Face Generation </b> <br />
[[Paper]](https://arxiv.org/abs/2106.12445) arxiv<br />
<sub><sup>Jihye Back</sup></sub><br />

ðŸ“„<b> Pivotal Tuning for Latent-based Editing of Real Images </b> <br />
[[Paper]](https://arxiv.org/abs/2106.05744)  [[Github]](https://github.com/danielroich/PTI) ACM<br />
<sub><sup>Daniel Roich, Ron Mokady, Amit H. Bermano, Daniel Cohen-Or</sup></sub><br />

ðŸ“„<b> Transforming the Latent Space of StyleGAN for Real Face Editing </b> <br />
[[Paper]](https://arxiv.org/abs/2105.14230)  [[Github]](https://github.com/AnonSubm2021/TransStyleGAN) arxiv<br />
<sub><sup>Heyi Li, Jinlong Liu, Xinyu Zhang, Yunzhi Bai, Huayan Wang, Klaus Mueller</sup></sub><br />

ðŸ“„<b> One Shot Face Swapping on Megapixels </b> <br />
[[Paper]](https://arxiv.org/abs/2105.04932)  [[Github]](https://github.com/zyainfal/One-Shot-Face-Swapping-on-Megapixels) CVPR<br />
<sub><sup>Yuhao Zhu, Qi Li, Jian Wang, Chengzhong Xu, Zhenan Sun</sup></sub><br />

ðŸ“„<b> ReStyle: A Residual-Based StyleGAN Encoder via Iterative Refinement </b> <br />
[[Paper]](https://arxiv.org/abs/2104.02699) [[Github]](https://github.com/yuval-alaluf/restyle-encoder) [[Video]](https://www.youtube.com/watch?v=6pGzLECSIWM) ICCV<br />
<sub><sup>Yuval Alaluf, Or Patashnik, Daniel Cohen-Or</sup></sub><br />

ðŸ“„<b> Designing an Encoder for StyleGAN Image Manipulation </b> <br />
[[Paper]](https://arxiv.org/abs/2102.02766) [[Github]](https://github.com/omertov/encoder4editing) [[Video]](https://dl.acm.org/doi/10.1145/3450626.3459838) arxiv<br />
<sub><sup>Omer Tov, Yuval Alaluf, Yotam Nitzan, Or Patashnik, Daniel Cohen-Or</sup></sub><br />

ðŸ“„<b> StyleCLIP: Text-Driven Manipulation of StyleGAN Imagery </b> <br />
[[Paper]](https://arxiv.org/abs/2103.17249) [[Github]](https://github.com/orpatashnik/StyleCLIP) [[Video]](https://www.youtube.com/watch?v=5icI0NgALnQ) IEEE/CVF<br />
<sub><sup>Or Patashnik, Zongze Wu, Eli Shechtman, Daniel Cohen-Or, Dani Lischinski</sup></sub><br />

ðŸ“„<b> StyleGAN-NADA: CLIP-Guided Domain Adaptation of Image Generators </b> <br />
[[Paper]](https://arxiv.org/abs/2108.00946)  [[Github]](https://github.com/rinongal/StyleGAN-nada) CoRR<br />
<sub><sup>Rinon Gal, Or Patashnik, Haggai Maron, Gal Chechik, Daniel Cohen-Or</sup></sub><br />

ðŸ“„<b> Alias-Free Generative Adversarial Networks </b> <br />
[[Paper]](https://arxiv.org/abs/2106.12423) [[Github]](https://github.com/NVlabs/stylegan3) [[Video]](https://nvlabs-fi-cdn.nvidia.com/stylegan3/videos/) NeurIPS<br />
<sub><sup>Tero Karras, Miika Aittala, Samuli Laine, Erik HÃƒÂ¤rkÃƒÂ¶nen, Janne Hellsten, Jaakko Lehtinen, Timo Aila</sup></sub><br />

ðŸ“„<b> Normalized Avatar Synthesis Using StyleGAN and Perceptual Refinement </b> <br />
[[Paper]](https://arxiv.org/abs/2106.11423)  [[Video]](https://www.youtube.com/watch?v=V9r_jOiGX84) IEEE/CVF<br />
<sub><sup>Huiwen Luo, Koki Nagano, Han-Wei Kung, Mclean Goldwhite, Qingguo Xu, Zejian Wang, Lingyu Wei, Liwen Hu, Hao Li</sup></sub><br />

ðŸ“„<b> Learning Transferable Visual Models From Natural Language Supervision </b> <br />
[[Paper]](https://arxiv.org/abs/2103.00020)  [[Github]](https://github.com/openai/CLIP) PMLR<br />
<sub><sup>Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, Gretchen Krueger, Ilya Sutskever</sup></sub><br />

ðŸ“„<b> StyleCariGAN: Caricature Generation via StyleGAN Feature Map Modulation </b> <br />
[[Paper]](https://arxiv.org/abs/2107.04331) [[Github]](https://github.com/wonjongg/StyleCariGAN) [[Video]](https://www.youtube.com/watch?v=kpHbGOlI-BU&feature=youtu.be) ACM<br />
<sub><sup>Wonjong Jang, Gwangjin Ju, Yucheol Jung, Jiaolong Yang, Xin Tong, Seungyong Lee</sup></sub><br />

ðŸ“„<b> Towards Real-World Blind Face Restoration with Generative Facial Prior </b> <br />
[[Paper]](https://arxiv.org/abs/2101.04061)  [[Github]](https://github.com/TencentARC/GFPGAN) IEEE/CVF<br />
<sub><sup>Xintao Wang, Yu Li, Honglun Zhang, Ying Shan</sup></sub><br />

ðŸ“„<b> Positional Encoding as Spatial Inductive Bias in GANs </b> <br />
[[Paper]](https://arxiv.org/abs/2012.05217) IEEE/CVF 2021<br />
<sub><sup>Rui Xu, Xintao Wang, Kai Chen, Bolei Zhou, Chen Change Loy</sup></sub><br />

ðŸ“„<b> Designing an Encoder for StyleGAN Image Manipulation </b> <br />
[[Paper]](https://arxiv.org/abs/2102.02766)  [[Github]](https://github.com/omertov/encoder4editing) ACM<br />
<sub><sup>Omer Tov, Yuval Alaluf, Yotam Nitzan, Or Patashnik, Daniel Cohen-Or</sup></sub><br />

ðŸ“„<b> BlendGAN: Implicitly GAN Blending for Arbitrary Stylized Face Generation </b> <br />
[[Paper]](https://arxiv.org/abs/2110.11728)  [[Github]](https://github.com/onion-liu/BlendGAN) Advances in Neural Information Processing Systems<br />
<sub><sup>Mingcong Liu, Qiang Li, Zekui Qin, Guoxin Zhang, Pengfei Wan, Wen Zheng</sup></sub><br />

ðŸ“„<b> StyleSpace Analysis: Disentangled Controls for StyleGAN Image Generation </b> <br />
[[Paper]](https://arxiv.org/abs/2011.12799) [[Github]](https://github.com/betterze/StyleSpace) [[Video]](https://www.youtube.com/watch?v=U7qRotRGr1w&feature=youtu.be) CVPR<br />
<sub><sup>Zongze Wu, Dani Lischinski, Eli Shechtman</sup></sub><br />

## 2020<br />

ðŸ“„<b> Encoding in Style: a StyleGAN Encoder for Image-to-Image Translation </b> <br />
[[Paper]](https://arxiv.org/abs/2008.00951) [[Github]](https://github.com/eladrich/pixel2style2pixel) [[Video]](https://www.youtube.com/watch?v=bfvSwhqsTgM) CVPR<br />
<sub><sup>Elad Richardson, Yuval Alaluf, Or Patashnik, Yotam Nitzan, Yaniv Azar, Stav Shapiro, Daniel Cohen-Or</sup></sub><br />

ðŸ“„<b> Training Generative Adversarial Networks with Limited Data </b> <br />
[[Paper]](https://arxiv.org/abs/2006.06676)  [[Github]](https://github.com/NVlabs/stylegan2-ada) arxiv<br />
<sub><sup>Tero Karras, Miika Aittala, Janne Hellsten, Samuli Laine, Jaakko Lehtinen, Timo Aila</sup></sub><br />

ðŸ“„<b> The Creation and Detection of Deepfakes: A Survey </b> <br />
[[Paper]](https://arxiv.org/abs/2004.11138) CSUR<br />
<sub><sup>Yisroel Mirsky, Wenke Lee</sup></sub><br />

ðŸ“„<b> StyleRig: Rigging StyleGAN for 3D Control over Portrait Images </b> <br />
[[Paper]](https://arxiv.org/abs/2004.00121) IEEE/CVF<br />
<sub><sup>Ayush Tewari, Mohamed Elgharib, Gaurav Bharaj, Florian Bernard, Hans-Peter Seidel, Patrick PÃƒÂ©rez, Michael ZollhÃƒÂ¶fer, Christian Theobalt</sup></sub><br />

ðŸ“„<b> Media Forensics and DeepFakes: an overview </b> <br />
[[Paper]](https://arxiv.org/abs/2001.06564) IEEE Journal of Selected Topics in Signal Processing<br />
<sub><sup>Luisa Verdoliva</sup></sub><br />

ðŸ“„<b> Neural Head Reenactment with Latent Pose Descriptors </b> <br />
[[Paper]](https://arxiv.org/abs/2004.12000)  [[Github]](https://github.com/shrubb/latent-pose-reenactment) CVPR<br />
<sub><sup>Egor Burkov, Igor Pasechnik, Artur Grigorev, Victor Lempitsky</sup></sub><br />

ðŸ“„<b> GAN Compression: Efficient Architectures for Interactive Conditional GANs </b> <br />
[[Paper]](https://arxiv.org/abs/2003.08936) [[Github]](https://github.com/mit-han-lab/gan-compression) [[Video]](https://www.youtube.com/playlist?list=PL80kAHvQbh-r5R8UmXhQK1ndqRvPNw_ex) CVPR<br />
<sub><sup>Muyang Li, Ji Lin, Yaoyao Ding, Zhijian Liu, Jun-Yan Zhu, Song Han</sup></sub><br />

ðŸ“„<b> StyleGAN2 Distillation for Feed-forward Image Manipulation </b> <br />
[[Paper]](https://arxiv.org/abs/2003.03581)  [[Github]](https://github.com/EvgenyKashin/stylegan2-distillation) Springer<br />
<sub><sup>Yuri Viazovetskyi, Vladimir Ivashkin, Evgeny Kashin </sup></sub><br />

ðŸ“„<b> Collaborative Learning for Faster StyleGAN Embedding </b> <br />
[[Paper]](https://arxiv.org/abs/2007.01758)  [[Github]](https://github.com/EvgenyKashin/stylegan2-distillation) arxiv<br />
<sub><sup>Shanyan Guan, Ying Tai, Bingbing Ni, Feida Zhu, Feiyue Huang, Xiaokang Yang</sup></sub><br />

ðŸ“„<b> In-Domain GAN Inversion for Real Image Editing </b> <br />
[[Paper]](https://arxiv.org/abs/2004.00049)  [[Github]](https://github.com/EvgenyKashin/stylegan2-distillation) arxiv<br />
<sub><sup>Jiapeng Zhu, Yujun Shen, Deli Zhao, Bolei Zhou</sup></sub><br />

ðŸ“„<b> Interpreting the Latent Space of GANs for Semantic Face Editing </b> <br />
[[Paper]](https://arxiv.org/abs/1907.10786) CVPR<br />
<sub><sup>Yujun Shen, Jinjin Gu, Xiaoou Tang, Bolei Zhou</sup></sub><br />

ðŸ“„<b> GANSpace: Discovering Interpretable GAN Controls </b> <br />
[[Paper]](https://arxiv.org/abs/2004.02546)  [[Github]](https://github.com/harskish/ganspace) Advances in Neural Information Processing Systems<br />
<sub><sup>Erik HÃƒÂ¤rkÃƒÂ¶nen, Aaron Hertzmann, Jaakko Lehtinen, Sylvain Paris</sup></sub><br />

ðŸ“„<b> Resolution Dependent GAN Interpolation for Controllable Image Synthesis Between Domains </b> <br />
[[Paper]](https://arxiv.org/abs/2010.05334) arxiv<br />
<sub><sup>Justin N. M. Pinkney, Doron Adler</sup></sub><br />

ðŸ“„<b> Advancing High Fidelity Identity Swapping for Forgery Detection </b> <br />
[[Paper]](https://openaccess.thecvf.com/content_CVPR_2020/html/Li_Advancing_High_Fidelity_Identity_Swapping_for_Forgery_Detection_CVPR_2020_paper.html) CVPR<br />
<sub><sup>Lingzhi Li, Jianmin Bao, Hao Yang, Dong Chen, Fang Wen</sup></sub><br />

## 2019<br />

ðŸ“„<b> Analyzing and Improving the Image Quality of StyleGAN </b> <br />
[[Paper]](https://arxiv.org/abs/1912.04958) [[Github]](https://github.com/NVlabs/stylegan2) [[Video]](https://www.youtube.com/watch?v=c-NJtV9Jvp0) IEEE/CVF<br />
<sub><sup>Tero Karras, Samuli Laine, Miika Aittala, Janne Hellsten, Jaakko Lehtinen, Timo Aila</sup></sub><br />

ðŸ“„<b> Unconstrained Facial Expression Transfer using Style-based Generator </b> <br />
[[Paper]](https://arxiv.org/abs/1912.06253) arxiv<br />
<sub><sup>Chao Yang, Ser-Nam Lim</sup></sub><br />

ðŸ“„<b> Image2StyleGAN++: How to Edit the Embedded Images? </b> <br />
[[Paper]](https://arxiv.org/abs/1911.11544)  [[Video]](https://www.youtube.com/watch?v=kEKVSMTTQEI) IEEE/CVF<br />
<sub><sup>Rameen Abdal, Yipeng Qin, Peter Wonka</sup></sub><br />

ðŸ“„<b> Deep Learning for Deepfakes Creation and Detection: A Survey </b> <br />
[[Paper]](https://arxiv.org/abs/1909.11573) arxiv<br />
<sub><sup>Thanh Thi Nguyen, Quoc Viet Hung Nguyen, Dung Tien Nguyen, Duc Thanh Nguyen, Thien Huynh-The, Saeid Nahavandi, Thanh Tam Nguyen, Quoc-Viet Pham, Cuong M. Nguyen</sup></sub><br />

ðŸ“„<b> Mining Audio, Text and Visual Information for Talking Face Generation </b> <br />
[[Paper]](https://ieeexplore.ieee.org/document/8970886) ICDM<br />
<sub><sup>L. Yu, J. Yu, and Q. Ling</sup></sub><br />

ðŸ“„<b> FReeNet: Multi-Identity Face Reenactment </b> <br />
[[Paper]](https://arxiv.org/abs/1905.11805) arxiv<br />
<sub><sup>Jiangning Zhang, Xianfang Zeng, Mengmeng Wang, Yusu Pan, Liang Liu, Yong Liu, Yu Ding, Changjie Fan</sup></sub><br />

## 2018<br />

ðŸ“„<b>  A Style-Based Generator Architecture for Generative Adversarial Networks </b> <br />
[[Paper]](https://arxiv.org/abs/1812.04948) [[Github]](https://github.com/NVlabs/stylegan) [[Video]](https://youtu.be/kSLJriaOumA) IEEE/CVF<br />
<sub><sup>Tero Karras, Samuli Laine, Timo Aila </sup></sub><br />

ðŸ“„<b> Video-to-Video Synthesis </b> <br />
[[Paper]](https://arxiv.org/abs/1808.06601) [[Github]](https://github.com/NVIDIA/vid2vid) [[Video]](https://www.youtube.com/watch?v=GrP_aOSXt5U) NeurIPS<br />
<sub><sup>Ting-Chun Wang, Ming-Yu Liu, Jun-Yan Zhu, Guilin Liu, Andrew Tao, Jan Kautz, Bryan Catanzaro</sup></sub><br />

ðŸ“„<b> End-to-End Speech-Driven Facial Animation with Temporal GANs </b> <br />
[[Paper]](https://arxiv.org/abs/1805.09313) BMVC<br />
<sub><sup>Konstantinos Vougioukas, Stavros Petridis, Maja Pantic </sup></sub><br />

ðŸ“„<b> Talking Face Generation by Conditional Recurrent Adversarial Network </b> <br />
[[Paper]](https://arxiv.org/abs/1804.04786)  [[Github]](https://github.com/susanqq/Talking_Face_Generation) arxiv<br />
<sub><sup>Yang Song, Jingwen Zhu, Dawei Li, Xiaolong Wang, Hairong Qi</sup></sub><br />

ðŸ“„<b> Unsupervised Depth Estimation, 3D Face Rotation and Replacement </b> <br />
[[Paper]](https://arxiv.org/abs/1803.09202)  [[Github]](https://github.com/joelmoniz/DepthNets) NeurIPS<br />
<sub><sup>Tero Karras, Samuli Laine, Timo Aila </sup></sub><br />

ðŸ“„<b> ArcFace: Additive Angular Margin Loss for Deep Face Recognition </b> <br />
[[Paper]](https://arxiv.org/abs/1801.07698)  [[Github]](https://github.com/deepinsight/insightface) IEEE/CVF<br />
<sub><sup>Jiankang Deng, Jia Guo, Jing Yang, Niannan Xue, Irene Kotsia, Stefanos Zafeiriou</sup></sub><br />

ðŸ“„<b> The Unreasonable Effectiveness of Deep Features as a Perceptual Metric </b> <br />
[[Paper]](https://arxiv.org/abs/1801.03924)  [[Github]](https://github.com/richzhang/PerceptualSimilarity) CVPR<br />
<sub><sup>Richard Zhang, Phillip Isola, Alexei A. Efros, Eli Shechtman, Oliver Wang</sup></sub><br />

ðŸ“„<b> Photorealistic Monocular Gaze Redirection Using Machine Learning </b> <br />
[[Paper]](https://ieeexplore.ieee.org/document/8010348) IEEE<br />
<sub><sup>D. Kononenko, Y. Ganin, D. Sungatullina, and V. Lempitsky</sup></sub><br />

## 2017<br />

ðŸ“„<b> The Perception-Distortion Tradeoff </b> <br />
[[Paper]](https://arxiv.org/abs/1711.06077) IEEE/CVPR<br />
<sub><sup>Yochai Blau, Tomer Michaeli</sup></sub><br />

ðŸ“„<b> Progressive Growing of GANs for Improved Quality, Stability, and Variation </b> <br />
[[Paper]](https://arxiv.org/abs/1710.10196)  [[Github]](https://github.com/tkarras/progressive_growing_of_gans) ICLR<br />
<sub><sup>Tero Karras, Timo Aila, Samuli Laine, Jaakko Lehtinen</sup></sub><br />

ðŸ“„<b> MoCoGAN: Decomposing Motion and Content for Video Generation </b> <br />
[[Paper]](https://arxiv.org/abs/1707.04993)  [[Github]](https://github.com/sergeytulyakov/mocogan) IEEE/CVF<br />
<sub><sup>Sergey Tulyakov, Ming-Yu Liu, Xiaodong Yang, Jan Kautz</sup></sub><br />

ðŸ“„<b> GANs Trained by a Two Time-Scale Update Rule Converge to a Local Nash Equilibrium </b> <br />
[[Paper]](https://arxiv.org/abs/1706.08500)  [[Github]](https://github.com/bioinf-jku/TTUR) Advances in neural information processing systems<br />
<sub><sup>Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, Sepp Hochreiter</sup></sub><br />

ðŸ“„<b> Representation Learning by Rotating Your Faces </b> <br />
[[Paper]](https://arxiv.org/abs/1705.11136) IEEE Transactions on Pattern Analysis and Machine Intelligence<br />
<sub><sup>Luan Tran, Xi Yin, Xiaoming Liu</sup></sub><br />

ðŸ“„<b> On Convergence and Stability of GANs </b> <br />
[[Paper]](https://arxiv.org/abs/1705.07215)  [[Github]](https://github.com/kodalinaveen3/DRAGAN) arxiv<br />
<sub><sup>Naveen Kodali, Jacob Abernethy, James Hays, Zsolt Kira</sup></sub><br />

ðŸ“„<b> Arbitrary Style Transfer in Real-time with Adaptive Instance Normalization </b> <br />
[[Paper]](https://arxiv.org/abs/1703.06868)  [[Github]](https://github.com/xunhuang1995/AdaIN-style) ICCV<br />
<sub><sup>Xun Huang, Serge Belongie</sup></sub><br />

ðŸ“„<b> Precise Recovery of Latent Vectors from Generative Adversarial Networks </b> <br />
[[Paper]](https://arxiv.org/abs/1702.04782) arxiv<br />
<sub><sup>Zachary C. Lipton, Subarna Tripathi</sup></sub><br />

ðŸ“„<b> Automated face swapping and its detection </b> <br />
[[Paper]](https://ieeexplore.ieee.org/abstract/document/8124497) ICSIP<br />
<sub><sup>Y. Zhang, L. Zheng, and V. L. L. Thing</sup></sub><br />

ðŸ“„<b> Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks </b> <br />
[[Paper]](https://arxiv.org/abs/1703.10593)  [[Github]](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix) CoRR<br />
<sub><sup>Jun-Yan Zhu, Taesung Park, Phillip Isola, Alexei A. Efros</sup></sub><br />

## 2016<br />

ðŸ“„<b> Perceptual Losses for Real-Time Style Transfer and Super-Resolution </b> <br />
[[Paper]](https://arxiv.org/abs/1603.08155) Springer<br />
<sub><sup>Justin Johnson, Alexandre Alahi, Li Fei-Fei</sup></sub><br />

ðŸ“„<b>  Face2Face: Real-time Face Capture and Reenactment of RGB Videos </b> <br />
[[Paper]](https://openaccess.thecvf.com/content_cvpr_2016/html/Thies_Face2Face_Real-Time_Face_CVPR_2016_paper.html) IEEE conference on computer vision and pattern recognition<br />
<sub><sup>Justus Thies, Michael ZollhÃƒÂ¶fer, Marc Stamminger, Christian Theobalt, Matthias NieÃƒÂŸner</sup></sub><br />



